# CSTSUNet
A Cross Swin Transformer Based Siamese U-Shape Network for Change Detection in Remote Sensing Images
Change detection (CD) in remote sensing images is a critical task that has achieved significant success by deep learning. However, current networks often represent changes of interest by merely pixel-based differencing, proportion, classification-based or feature concatenation methods, which are sensitive to factors such as atmospheric environment, lighting, and phenology, resulting in detection errors. Inspired by the Transformer structure, we adopt a cross-attention mechanism to more robustly extract feature differences between bitemporal images. The motivation of the method is based on the assumption that if there is no change between image pairs, the semantic features from one temporal image can well be represented by the semantic features from another temporal image. Conversely if there is a change, there will be significant reconstruction errors. Therefore, we propose a Cross Swin Transformer based Siamese U-shaped network namely CSTSUNet for remote sensing change detection. CSTSUnet consists of encoder, difference feature extraction, and decoder. The encoder is based on a hierarchical Resnet with the Siamese U-net structure, allowing parallel processing of bitemporal images and extraction of multi-scale features. The difference feature extraction consists of four difference feature extraction modules that compute difference feature at multiple scales. In this module, Cross Swin Transformer is employed in each difference feature extraction module to communicate the information of bitemporal images. The decoder takes in the multi-scale difference features as input, injects details and boundaries iteratively level by level, and makes the change map more and more accurate. We conducted experiments on three public datasets, and the experimental results show that our CSTSUNet outperforms other state-of-the-art methods in terms of both qualitative and quantitative analyses.

The code will be released soon!
